<html>

<head>
    <link rel="stylesheet" href="styles.css">
    <title>22wi CSE 455: ImgToChunk</title>
</head>
    
<body>
    <main>
        <h1>22wi CSE 455: ImgToChunk</h1>
        <section>
            <h2>Expectations</h2>
            Pick any area of computer vision that interests you and pursue some independent work in that area. Each project should have a significant technical component,
            software implementation, or large-scale study. Projects can focus on developing new techniques or tools in computer vision or applying existing tools to a new
            domain. If you don't have an idea you can train a classifier on birds and compete in the Kaggle competition posted on the Ed discussion board.
        </section>
        <section>
            <h2>Initial Proposal</h2>
            My final project is Minecraft map generation from timelapse videos using CNN based depth estimation techniques. To specify, I will train a supervised CNN-based
            monocular depth estimator that takes in a RGB image of a gameplay screenshot in Minecraft and produces the depth image of that scene with the same dimensions.
            I will follow the architecture proposed in a paper from 2014, Depth Map Prediction from a Single Image using a Multi-Scale Deep Network
            (https://arxiv.org/abs/1406.2283), which involves two relatively light-weight CNN models that predict the “global coarse-scale” and the “local fine-scale”
            features. The training and test data can easily be generated by using Replay Mod, which allows for capturing Minecraft renders in png sequences, and Shader Mod,
            which allows for custom shaders that can render grayscale depth view instead of the default RGB view.
        </section>
        <section>
            <h2>Prior Works</h2>
            Single image depth estimation, like any other problems in computer vision, moved from hand-coded feature extractors from the early days to more neural network
            based models.<br>
            One of the earliest works, Automatic Photo Pop-up by Hoiem et al from 2005 (https://dhoiem.cs.illinois.edu/publications/popup.pdf), use methods such as
            "difference of offset guassian" (DOOG) filters and parallel edge/line counts to detect surfaces, planes, and vanishing points from the viewer's point of view.<br>
            <img src="images/CMU.gif" alt="CMU from Pop-up">
        </section>
        <section>
            <h2>Approaches</h2>
            <h3>Limitations of using shader generated depth data</h3>
        </section>
        <section>
            <h2>Video Demonstration</h2>
        </section>
        <section>
            <h2>Code and Implementation</h2>
        </section>
    </main>
</body>

</html>
